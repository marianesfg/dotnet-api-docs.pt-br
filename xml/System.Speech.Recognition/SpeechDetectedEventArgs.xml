<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechDetectedEventArgs.xml" source-language="en-US" target-language="pt-BR">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5319a6fac2a70dc60263255b2ed9c3276379768f5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">319a6fac2a70dc60263255b2ed9c3276379768f5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>Returns data from <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected" /&gt;</ph> or <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" /&gt;</ph> events.</source>
          
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>A <ph id="ph1">`SpeechDetected`</ph> event is raised by the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> classes.</source>
          <target state="translated">Um <ph id="ph1">`SpeechDetected`</ph> é gerado pelo <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> e <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> classes.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source><bpt id="p1">**</bpt>SpeechDetected<ept id="p1">**</ept> events are generated when a recognition engine can identify audio input as human speech.</source>
          <target state="translated"><bpt id="p1">**</bpt>SpeechDetected<ept id="p1">**</ept> eventos são gerados quando um mecanismo de reconhecimento pode identificar a entrada de áudio como fala humana.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> derives from <ph id="ph2">&lt;xref:System.EventArgs&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> deriva de <ph id="ph2">&lt;xref:System.EventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>The example below creates a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> events.</source>
          <target state="translated">O exemplo a seguir cria um manipulador para <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> ou <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> eventos.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechDetectedEventArgs">
          <source>The handler initializes a display every time speech is detected and displays status information, including audio position.</source>
          <target state="translated">O manipulador inicializa uma exibição sempre que a fala é detectada e exibe informações de status, incluindo a posição de áudio.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>Gets the position in the audio stream where speech was detected.</source>
          
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>Returns the location of a detected phrase within a recognition engine’s speech buffer.</source>
          <target state="translated">Retorna o local de uma frase detectado no buffer de um mecanismo de reconhecimento fala.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>The example below creates a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> events.</source>
          <target state="translated">O exemplo a seguir cria um manipulador para <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected?displayProperty=nameWithType&gt;</ph> ou <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected?displayProperty=nameWithType&gt;</ph> eventos.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition">
          <source>The handler initializes a display each time speech is detected and displays status information, including audio position.</source>
          <target state="translated">O manipulador inicializa uma exibição fala cada vez é detectada e exibe informações de status, incluindo a posição de áudio.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>